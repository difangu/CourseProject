{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "df_raw = spark.read.options(header='False',wholetext=True)\\\r\n",
        "    .text('adl://cp-bizops-c15.azuredatalakestore.net/local/users/lowen/UIUC/dblp.xml')\r\n",
        "#df_raw['value_1']=df_raw['value'].apply(lambda x: ' '.join(x) )\r\n",
        "\r\n",
        "#df_text=' '.join(df_raw['value_1'])\r\n",
        "#df_raw.write.mode(\"overwrite\").saveAsTable(\"default.dblp\")\r\n",
        "df_raw.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkpool3",
              "session_id": 13,
              "statement_id": 3,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2020-12-02T00:19:37.7898633Z",
              "execution_start_time": "2020-12-02T00:20:43.3379768Z",
              "execution_finish_time": "2020-12-02T00:20:57.5794507Z"
            },
            "text/plain": "StatementMeta(sparkpool3, 13, 3, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 146,
          "data": {
            "text/plain": "+--------------------+\n|               value|\n+--------------------+\n|<?xml version=\"1....|\n|<!DOCTYPE dblp SY...|\n|              <dblp>|\n|<phdthesis mdate=...|\n|<author>Carmen He...|\n|<title>Modell zur...|\n|   <year>2010</year>|\n|<school>Aarhus Un...|\n|<pages>1-315</pages>|\n|<isbn>978-3-86596...|\n|<ee>http://d-nb.i...|\n|</phdthesis><phdt...|\n|<author>Gerd Hoff...|\n|<title>Ein Verfah...|\n|   <year>2002</year>|\n|<school>Universit...|\n|<ee>http://ubt.op...|\n|<ee>https://nbn-r...|\n|<ee>http://d-nb.i...|\n|        </phdthesis>|\n+--------------------+\nonly showing top 20 rows"
          },
          "metadata": {}
        }
      ],
      "execution_count": 146,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=df_raw.select('value').collect()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkpool3",
              "session_id": 13,
              "statement_id": 4,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2020-12-02T00:19:41.2847946Z",
              "execution_start_time": "2020-12-02T00:20:57.6061868Z",
              "execution_finish_time": "2020-12-02T00:26:52.5813786Z"
            },
            "text/plain": "StatementMeta(sparkpool3, 13, 4, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 147,
          "data": {
            "text/plain": ""
          },
          "metadata": {}
        }
      ],
      "execution_count": 147,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mstr=\"\"\r\n",
        "flag=False\r\n",
        "dblp=[]\r\n",
        "for row in df:\r\n",
        "    s=str(row.value)\r\n",
        "    if s.__contains__('</phdthesis>'):\r\n",
        "        i=s.index('</phdthesis>')\r\n",
        "        s1=s[0:i+len('</phdthesis>')]\r\n",
        "        mstr=mstr+s1\r\n",
        "        dblp.append(mstr)\r\n",
        "        mstr=\"\"\r\n",
        "        flag=False\r\n",
        "    if s.__contains__('<phdthesis'):\r\n",
        "        i=s.index('<phdthesis')\r\n",
        "        mstr=mstr+s[i:]\r\n",
        "        flag=True\r\n",
        "    else:\r\n",
        "        if flag==True:\r\n",
        "            mstr=mstr+s"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkpool3",
              "session_id": 13,
              "statement_id": 5,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2020-12-02T00:19:43.9909487Z",
              "execution_start_time": "2020-12-02T00:26:52.6071199Z",
              "execution_finish_time": "2020-12-02T00:29:31.8812743Z"
            },
            "text/plain": "StatementMeta(sparkpool3, 13, 5, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 148,
          "data": {
            "text/plain": ""
          },
          "metadata": {}
        }
      ],
      "execution_count": 148,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dblp[:2]"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkpool3",
              "session_id": 13,
              "statement_id": 6,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2020-12-02T00:19:48.2748858Z",
              "execution_start_time": "2020-12-02T00:29:31.9566358Z",
              "execution_finish_time": "2020-12-02T00:29:33.990727Z"
            },
            "text/plain": "StatementMeta(sparkpool3, 13, 6, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 149,
          "data": {
            "text/plain": "['<phdthesis mdate=\"2016-05-04\" key=\"phd/dk/Heine2010\"><author>Carmen Heine</author><title>Modell zur Produktion von Online-Hilfen.</title><year>2010</year><school>Aarhus University</school><pages>1-315</pages><isbn>978-3-86596-263-8</isbn><ee>http://d-nb.info/996064095</ee></phdthesis>', '<phdthesis mdate=\"2020-02-12\" key=\"phd/Hoff2002\"><author>Gerd Hoff</author><title>Ein Verfahren zur thematisch spezialisierten Suche im Web und seine Realisierung im Prototypen HomePageSearch</title><year>2002</year><school>University of Trier, Germany</school><ee>http://ubt.opus.hbz-nrw.de/volltexte/2004/146/</ee><ee>https://nbn-resolving.org/urn:nbn:de:hbz:385-1468</ee><ee>http://d-nb.info/971713243</ee></phdthesis>']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 149,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET \r\n",
        "list_dblp=[]\r\n",
        "for d in dblp:\r\n",
        "    dict_dblp={}\r\n",
        "    try:\r\n",
        "        tree = ET.fromstring(d.replace('&','')) \r\n",
        "        for child in tree:\r\n",
        "            #print(child.tag, ' '.join(child.itertext()))\r\n",
        "            dict_dblp[child.tag]=' '.join(child.itertext())\r\n",
        "        list_dblp.append(dict_dblp)\r\n",
        "    except :\r\n",
        "        print(d)\r\n",
        "\r\n",
        "list_dblp[:2]"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkpool3",
              "session_id": 13,
              "statement_id": 7,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2020-12-02T00:19:50.7357187Z",
              "execution_start_time": "2020-12-02T00:29:34.0196222Z",
              "execution_finish_time": "2020-12-02T00:29:36.0506016Z"
            },
            "text/plain": "StatementMeta(sparkpool3, 13, 7, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 150,
          "data": {
            "text/plain": "[{'author': 'Carmen Heine', 'title': 'Modell zur Produktion von Online-Hilfen.', 'year': '2010', 'school': 'Aarhus University', 'pages': '1-315', 'isbn': '978-3-86596-263-8', 'ee': 'http://d-nb.info/996064095'}, {'author': 'Gerd Hoff', 'title': 'Ein Verfahren zur thematisch spezialisierten Suche im Web und seine Realisierung im Prototypen HomePageSearch', 'year': '2002', 'school': 'University of Trier, Germany', 'ee': 'http://d-nb.info/971713243'}]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 150,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET \r\n",
        "list_dblp_together=[]\r\n",
        "for d in dblp:\r\n",
        "    dict_dblp={}\r\n",
        "    try:\r\n",
        "        tree = ET.fromstring(d.replace('&','')) \r\n",
        "        #dict_dblp[child.tag]=' '.join(child.itertext())\r\n",
        "        list_dblp_together.append([' '.join(tree.itertext())])\r\n",
        "    except :\r\n",
        "        print(d)\r\n",
        "\r\n",
        "list_dblp_together[:2]"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkpool3",
              "session_id": 13,
              "statement_id": 25,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2020-12-02T00:56:14.3185465Z",
              "execution_start_time": "2020-12-02T00:56:14.3501981Z",
              "execution_finish_time": "2020-12-02T00:56:16.3768067Z"
            },
            "text/plain": "StatementMeta(sparkpool3, 13, 25, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 168,
          "data": {
            "text/plain": "[['Carmen Heine Modell zur Produktion von Online-Hilfen. 2010 Aarhus University 1-315 978-3-86596-263-8 http://d-nb.info/996064095'], ['Gerd Hoff Ein Verfahren zur thematisch spezialisierten Suche im Web und seine Realisierung im Prototypen HomePageSearch 2002 University of Trier, Germany http://ubt.opus.hbz-nrw.de/volltexte/2004/146/ https://nbn-resolving.org/urn:nbn:de:hbz:385-1468 http://d-nb.info/971713243']]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 168,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns = [\"value\"]\r\n",
        "\r\n",
        "df_all = spark.createDataFrame(data=list_dblp_together,schema =columns)\r\n",
        "df_all.coalesce(1).write.format(\"text\").option(\"header\", \"false\").mode(\"overwrite\").save('adl://cp-bizops-c15.azuredatalakestore.net/local/users/lowen/UIUC/dblp_all.txt')\r\n",
        "\r\n",
        "df_sample = spark.createDataFrame(data=list_dblp_together[:500],schema =columns)\r\n",
        "df_sample.coalesce(1).write.format(\"text\").option(\"header\", \"false\").mode(\"overwrite\").save('adl://cp-bizops-c15.azuredatalakestore.net/local/users/lowen/UIUC/dblp_sample.txt')\r\n",
        "\r\n",
        "print(len(list_dblp),len(list_dblp_together),df_all.count(),df_sample.count())"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkpool3",
              "session_id": 13,
              "statement_id": 35,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2020-12-02T01:16:22.4711454Z",
              "execution_start_time": "2020-12-02T01:16:22.5007889Z",
              "execution_finish_time": "2020-12-02T01:16:30.6304537Z"
            },
            "text/plain": "StatementMeta(sparkpool3, 13, 35, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 178,
          "data": {
            "text/plain": "78704 78704 78704 500"
          },
          "metadata": {}
        }
      ],
      "execution_count": 178,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(df_all.limit(5))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkpool3",
              "session_id": 13,
              "statement_id": 28,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2020-12-02T00:56:54.8121556Z",
              "execution_start_time": "2020-12-02T00:56:54.8423308Z",
              "execution_finish_time": "2020-12-02T00:56:56.8913427Z"
            },
            "text/plain": "StatementMeta(sparkpool3, 13, 28, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.synapse.widget-view+json": {
              "widget_id": "df13e881-31b7-4f4e-9e46-04d2a61e321e",
              "widget_type": "Synapse.DataFrame"
            },
            "text/plain": "SynapseWidget(Synapse.DataFrame, df13e881-31b7-4f4e-9e46-04d2a61e321e)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 171,
          "data": {},
          "metadata": {}
        }
      ],
      "execution_count": 171,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import pandas as pd \r\n",
        "#df_dblp=pd.DataFrame.from_dict(list_dblp[:1])\r\n",
        "\r\n",
        "#i=0\r\n",
        "#for row in list_dblp[1:]:\r\n",
        "#    df_dblp=df_dblp.append(row,ignore_index=True)\r\n",
        "#    i=i+1\r\n",
        "#    if i>2:\r\n",
        "#        break"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkpool3",
              "session_id": 12,
              "statement_id": 58,
              "state": "finished",
              "livy_statement_state": "cancelled",
              "queued_time": "2020-12-02T00:14:37.8001599Z",
              "execution_start_time": "2020-12-02T00:14:37.828807Z",
              "execution_finish_time": "2020-12-02T00:16:44.0505942Z"
            },
            "text/plain": "StatementMeta(sparkpool3, 12, 58, Finished, Cancelled)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 143,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import pandas as pd \r\n",
        "#df_dblp=pd.DataFrame.from_dict(list_dblp[:1])\r\n",
        "#display(df_dblp)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkpool3",
              "session_id": 13,
              "statement_id": 20,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2020-12-02T00:45:38.3603201Z",
              "execution_start_time": "2020-12-02T00:45:38.3903408Z",
              "execution_finish_time": "2020-12-02T00:45:48.7125338Z"
            },
            "text/plain": "StatementMeta(sparkpool3, 13, 20, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.synapse.widget-view+json": {
              "widget_id": "a8f2686c-e46d-48fa-81cb-3acc3864e767",
              "widget_type": "Synapse.DataFrame"
            },
            "text/plain": "SynapseWidget(Synapse.DataFrame, a8f2686c-e46d-48fa-81cb-3acc3864e767)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\n/opt/spark/python/lib/pyspark.zip/pyspark/sql/session.py:714: UserWarning: createDataFrame attempted Arrow optimization because 'spark.sql.execution.arrow.enabled' is set to true; however, failed by the reason below:\n  'JavaPackage' object is not callable\nAttempting non-optimization as 'spark.sql.execution.arrow.fallback.enabled' is set to true.\n  warnings.warn(msg)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 163,
          "data": {},
          "metadata": {}
        }
      ],
      "execution_count": 163,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "saveOutput": true,
    "language_info": {
      "name": "scala",
      "version": "2.11.12",
      "mimetype": "text/x-scala",
      "file_extension": ".scala",
      "pygments_lexer": "scala",
      "codemirror_mode": "scala",
      "nbconvert_exporter": "scala"
    },
    "microsoft": {
      "language": "python"
    },
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}