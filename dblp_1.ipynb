{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "df_raw = spark.read.options(header='False',wholetext=True)\\\r\n",
        "    .text('adl://cp-bizops-c15.azuredatalakestore.net/local/users/lowen/UIUC/dblp.xml')\r\n",
        "df_raw.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkpool3",
              "session_id": 26,
              "statement_id": 3,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2020-12-08T02:54:42.0661331Z",
              "execution_start_time": "2020-12-08T02:58:10.0877221Z",
              "execution_finish_time": "2020-12-08T02:58:26.3869619Z"
            },
            "text/plain": "StatementMeta(sparkpool3, 26, 3, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": "+--------------------+\n|               value|\n+--------------------+\n|<?xml version=\"1....|\n|<!DOCTYPE dblp SY...|\n|              <dblp>|\n|<phdthesis mdate=...|\n|<author>Carmen He...|\n|<title>Modell zur...|\n|   <year>2010</year>|\n|<school>Aarhus Un...|\n|<pages>1-315</pages>|\n|<isbn>978-3-86596...|\n|<ee>http://d-nb.i...|\n|</phdthesis><phdt...|\n|<author>Gerd Hoff...|\n|<title>Ein Verfah...|\n|   <year>2002</year>|\n|<school>Universit...|\n|<ee>http://ubt.op...|\n|<ee>https://nbn-r...|\n|<ee>http://d-nb.i...|\n|        </phdthesis>|\n+--------------------+\nonly showing top 20 rows"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=df_raw.select('value').collect()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkpool3",
              "session_id": 26,
              "statement_id": 4,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2020-12-08T02:58:36.2907246Z",
              "execution_start_time": "2020-12-08T02:58:36.3248435Z",
              "execution_finish_time": "2020-12-08T03:04:06.8561081Z"
            },
            "text/plain": "StatementMeta(sparkpool3, 26, 4, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": ""
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mstr=\"\"\r\n",
        "flag=False\r\n",
        "dblp=[]\r\n",
        "for row in df:\r\n",
        "    s=str(row.value)\r\n",
        "    if s.__contains__('</phdthesis>'):\r\n",
        "        i=s.index('</phdthesis>')\r\n",
        "        s1=s[0:i+len('</phdthesis>')]\r\n",
        "        mstr=mstr+s1\r\n",
        "        dblp.append(mstr)\r\n",
        "        mstr=\"\"\r\n",
        "        flag=False\r\n",
        "    if s.__contains__('<phdthesis'):\r\n",
        "        i=s.index('<phdthesis')\r\n",
        "        mstr=mstr+s[i:]\r\n",
        "        flag=True\r\n",
        "    else:\r\n",
        "        if flag==True:\r\n",
        "            mstr=mstr+s"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkpool3",
              "session_id": 26,
              "statement_id": 5,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2020-12-08T03:04:17.4819513Z",
              "execution_start_time": "2020-12-08T03:04:17.512593Z",
              "execution_finish_time": "2020-12-08T03:06:58.6666006Z"
            },
            "text/plain": "StatementMeta(sparkpool3, 26, 5, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": ""
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET \r\n",
        "list_dblp=[]\r\n",
        "for d in dblp:\r\n",
        "    dict_dblp={}\r\n",
        "    try:\r\n",
        "        tree = ET.fromstring(d.replace('&','')) \r\n",
        "        for child in tree:\r\n",
        "            #print(child.tag, ' '.join(child.itertext()))\r\n",
        "            dict_dblp[child.tag]=' '.join(child.itertext())\r\n",
        "        list_dblp.append(dict_dblp)\r\n",
        "    except :\r\n",
        "        print(d)\r\n",
        "\r\n",
        "list_dblp[:2]"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkpool3",
              "session_id": 26,
              "statement_id": 6,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2020-12-08T03:04:37.9303743Z",
              "execution_start_time": "2020-12-08T03:06:58.6980499Z",
              "execution_finish_time": "2020-12-08T03:07:00.7286529Z"
            },
            "text/plain": "StatementMeta(sparkpool3, 26, 6, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "[{'author': 'Carmen Heine', 'title': 'Modell zur Produktion von Online-Hilfen.', 'year': '2010', 'school': 'Aarhus University', 'pages': '1-315', 'isbn': '978-3-86596-263-8', 'ee': 'http://d-nb.info/996064095'}, {'author': 'Gerd Hoff', 'title': 'Ein Verfahren zur thematisch spezialisierten Suche im Web und seine Realisierung im Prototypen HomePageSearch', 'year': '2002', 'school': 'University of Trier, Germany', 'ee': 'http://d-nb.info/971713243'}]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###get the list of author & title\r\n",
        "list_school_title=[]\r\n",
        "list_school=[]\r\n",
        "list_title=[]\r\n",
        "for l in list_dblp:\r\n",
        "    list_school_title.append([l.get('school'),l.get('title')])\r\n",
        "print(list_school_title[:3])\r\n",
        "\r\n",
        "for a in list_school_title:\r\n",
        "    list_school.append(a[0])\r\n",
        "list_school[:3]\r\n",
        "\r\n",
        "for a in list_school_title:\r\n",
        "    list_title.append(a[1])\r\n",
        "list_title[:3]\r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkpool3",
              "session_id": 26,
              "statement_id": 15,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2020-12-08T03:32:03.6992345Z",
              "execution_start_time": "2020-12-08T03:32:03.7286667Z",
              "execution_finish_time": "2020-12-08T03:32:05.7798858Z"
            },
            "text/plain": "StatementMeta(sparkpool3, 26, 15, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "[['Aarhus University', 'Modell zur Produktion von Online-Hilfen.'], ['University of Trier, Germany', 'Ein Verfahren zur thematisch spezialisierten Suche im Web und seine Realisierung im Prototypen HomePageSearch'], ['University of California at Berkeley', 'File System Performance and Transaction Support.']]\n['Modell zur Produktion von Online-Hilfen.', 'Ein Verfahren zur thematisch spezialisierten Suche im Web und seine Realisierung im Prototypen HomePageSearch', 'File System Performance and Transaction Support.']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###get the top author\r\n",
        "from collections import Counter\r\n",
        "dict_school={}\r\n",
        "for auth in list_school:\r\n",
        "    dict_school[auth]=dict_school.get(auth,0)+1\r\n",
        "\r\n",
        "dict_school_count=Counter(dict_school)\r\n",
        "dict_school_topcount=dict_school_count.most_common(200)\r\n",
        "\r\n",
        "#top_words=[w[0] for w in top_words]\r\n",
        "###2. deal with the two words phrase\r\n",
        "\r\n",
        "dict_school_topcount[:50]"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkpool3",
              "session_id": 26,
              "statement_id": 17,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2020-12-08T03:34:00.7761624Z",
              "execution_start_time": "2020-12-08T03:34:00.8047177Z",
              "execution_finish_time": "2020-12-08T03:34:02.8353908Z"
            },
            "text/plain": "StatementMeta(sparkpool3, 26, 17, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "[('Massachusetts Institute of Technology, Cambridge, MA, USA', 2165), ('Technical University Munich, Germany', 1114), ('Georgia Institute of Technology, Atlanta, GA, USA', 1100), ('Dresden University of Technology, Germany', 1039), ('University of Satilde;o Paulo, Brazil', 1012), ('RWTH Aachen University, Germany', 1009), ('Karlsruhe Institute of Technology, Germany', 983), ('Darmstadt University of Technology, Germany', 964), ('Joseph Fourier University, Grenoble, France', 953), ('University of Maryland, College Park, MD, USA', 855), ('Technical University of Berlin, Germany', 842), ('Imperial College London, UK', 744), ('Grenoble Institute of Technology, France', 731), ('University of Campinas, Brazil', 711), ('University of Southampton, UK', 680), ('University of Stuttgart, Germany', 679), ('Grenoble Alpes University, France', 672), ('University of Edinburgh, UK', 660), ('University of Rennes 1, France', 654), ('Technical University Munich', 629), ('University of Erlangen-Nuremberg, Germany', 622), ('University of Waterloo, Ontario, Canada', 600), ('Karlsruhe Institute of Technology', 578), ('University of Paris-Saclay, France', 558), ('Pierre and Marie Curie University, Paris, France', 556), ('University of California, San Diego, USA', 545), ('University of New South Wales, Sydney, Australia', 520), ('University of Cambridge, UK', 519), ('University of Oxford, UK', 517), ('Saarland University, Saarbruuml;cken, Germany', 505), ('Kaiserslautern University of Technology, Germany', 455), ('University College London, UK', 447), ('University of York, UK', 435), ('Berlin Institute of Technology', 416), ('University of Bordeaux, France', 399), ('Paul Sabatier University, Toulouse, France', 397), ('Saarland University', 396), ('University of Nottingham, UK', 389), ('Technical University of Dortmund, Germany', 384), ('University of Manchester, UK', 382), ('Virginia Tech, Blacksburg, VA, USA', 380), ('University of Nice Sophia Antipolis, France', 379), ('University of Paris-Sud, Orsay, France', 365), ('University of California, Berkeley, USA', 365), ('University of Glasgow, UK', 360), ('Ludwig Maximilian University of Munich, Germany', 358), ('University of Paderborn, Germany', 353), ('University of Bonn, Germany', 350), ('Arizona State University, Tempe, USA', 348), ('RWTH Aachen University', 346)]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import corpora\r\n",
        "### data cleaning for title\r\n",
        "from gensim.utils import simple_preprocess\r\n",
        "list_title_clean = [simple_preprocess(doc) for doc in list_title]\r\n",
        "##remove words with length<=3\r\n",
        "list_title_clean=[[w for w in s if len(w)>3]  for s in list_title_clean ]\r\n",
        "##stop words\r\n",
        "stopword=['http','https','university', 'info']\r\n",
        "list_title_clean=[[w for w in s if w not in stopword]  for s in list_title_clean ]\r\n",
        "\r\n",
        "#dct = corpora.Dictionary(list_title_clean)\r\n",
        "\r\n",
        "#corpus = [dct.doc2bow(line) for line in tokenized_list]\r\n",
        "#corpus[:1]\r\n",
        "\r\n",
        "list_title_clean[:3]"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkpool3",
              "session_id": 26,
              "statement_id": 22,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2020-12-08T03:40:38.9995367Z",
              "execution_start_time": "2020-12-08T03:40:39.0269774Z",
              "execution_finish_time": "2020-12-08T03:40:43.1052119Z"
            },
            "text/plain": "StatementMeta(sparkpool3, 26, 22, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": "[['modell', 'produktion', 'online', 'hilfen'], ['verfahren', 'thematisch', 'spezialisierten', 'suche', 'seine', 'realisierung', 'prototypen', 'homepagesearch'], ['file', 'system', 'performance', 'transaction', 'support']]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###1. get the dictionary for all data\r\n",
        "from collections import Counter\r\n",
        "##1.1. get the (word, count) pair dictionary\r\n",
        "dictionary={}\r\n",
        "\r\n",
        "for s in list_title_clean:\r\n",
        "    for w in s:\r\n",
        "        dictionary[w]=dictionary.get(w,0)+1\r\n",
        "##1.2. sorting to get the top 500 words\r\n",
        "top_words=Counter(dictionary)\r\n",
        "top_words=top_words.most_common(200)\r\n",
        "#topwords_dict\r\n",
        "top_words=[w[0] for w in top_words]\r\n",
        "###2. deal with the two words phrase\r\n",
        "top_words[:10]\r\n",
        "\r\n",
        "word_dict={}\r\n",
        "i=1\r\n",
        "for word in top_words:\r\n",
        "    word_dict[word]=i\r\n",
        "    i=i+1\r\n",
        "#print(word_dict.get('germany'))\r\n",
        "word_dict\r\n",
        "                                                                "
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkpool3",
              "session_id": 26,
              "statement_id": 26,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2020-12-08T03:45:35.5601897Z",
              "execution_start_time": "2020-12-08T03:45:35.5885816Z",
              "execution_finish_time": "2020-12-08T03:45:37.6245329Z"
            },
            "text/plain": "StatementMeta(sparkpool3, 26, 26, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 24,
          "data": {
            "text/plain": "{'systems': 1, 'based': 2, 'pour': 3, 'fuuml': 4, 'agrave': 5, 'data': 6, 'analysis': 7, 'networks': 8, 'with': 9, 'atilde': 10, 'reacute': 11, 'application': 12, 'applications': 13, 'design': 14, 'eacute': 15, 'learning': 16, 'using': 17, 'multi': 18, 'system': 19, 'dans': 20, 'information': 21, 'software': 22, 'deacute': 23, 'model': 24, 'models': 25, 'approach': 26, 'meacute': 27, 'systegrave': 28, 'algorithms': 29, 'analyse': 30, 'simulation': 31, 'from': 32, 'methods': 33, 'time': 34, 'management': 35, 'control': 36, 'modeling': 37, 'distributed': 38, 'eines': 39, 'performance': 40, 'computer': 41, 'image': 42, 'techniques': 43, 'network': 44, 'framework': 45, 'development': 46, 'wireless': 47, 'efficient': 48, 'optimization': 49, 'detection': 50, 'images': 51, 'dynamic': 52, 'processing': 53, 'para': 54, 'mobile': 55, 'recognition': 56, 'entwicklung': 57, 'modegrave': 58, 'modelling': 59, 'lisation': 60, 'high': 61, 'modeacute': 62, 'architecture': 63, 'communication': 64, 'machine': 65, 'evaluation': 66, 'seaux': 67, 'seacute': 68, 'real': 69, 'programming': 70, 'knowledge': 71, 'service': 72, 'computing': 73, 'security': 74, 'study': 75, 'adaptive': 76, 'parallel': 77, 'human': 78, 'language': 79, 'automatic': 80, 'geacute': 81, 'donneacute': 82, 'optimisation': 83, 'einer': 84, 'interaction': 85, 'large': 86, 'eine': 87, 'problems': 88, 'support': 89, 'neural': 90, 'environments': 91, 'estimation': 92, 'object': 93, 'visual': 94, 'architectures': 95, 'user': 96, 'classification': 97, 'towards': 98, 'internet': 99, 'services': 100, 'virtual': 101, 'unter': 102, 'systeme': 103, 'integration': 104, 'digital': 105, 'contribution': 106, 'engineering': 107, 'video': 108, 'implementation': 109, 'conception': 110, 'oriented': 111, 'theory': 112, 'computational': 113, 'interactive': 114, 'beitrag': 115, 'semantic': 116, 'generation': 117, 'verification': 118, 'process': 119, 'context': 120, 'sensor': 121, 'approche': 122, 'agent': 123, 'scale': 124, 'beispiel': 125, 'durch': 126, 'anwendung': 127, 'level': 128, 'quality': 129, 'resource': 130, 'memory': 131, 'scheduling': 132, 'energy': 133, 'vision': 134, 'uuml': 135, 'cloud': 136, 'decision': 137, 'social': 138, 'approaches': 139, 'structures': 140, 'driven': 141, 'entwurf': 142, 'segmentation': 143, 'reconstruction': 144, 'environment': 145, 'teacute': 146, 'neacute': 147, 'formal': 148, 'retrieval': 149, 'thodes': 150, 'complex': 151, 'mining': 152, 'tzung': 153, 'hardware': 154, 'modellierung': 155, 'logic': 156, 'avec': 157, 'informaccedil': 158, 'verfahren': 159, 'embedded': 160, 'otilde': 161, 'graph': 162, 'through': 163, 'multiple': 164, 'extraction': 165, 'identification': 166, 'heterogeneous': 167, 'structure': 168, 'robust': 169, 'tzte': 170, 'search': 171, 'online': 172, 'tzten': 173, 'apprentissage': 174, 'self': 175, 'aware': 176, 'domain': 177, 'systemen': 178, 'method': 179, 'problem': 180, 'planning': 181, 'linear': 182, 'synthesis': 183, 'veacute': 184, 'basis': 185, 'temporal': 186, 'power': 187, 'speech': 188, 'routing': 189, 'contributions': 190, 'hybrid': 191, 'automatique': 192, 'baseacute': 193, 'statistical': 194, 'preacute': 195, 'programs': 196, 'numeacute': 197, 'automated': 198, 'communications': 199, 'algorithmes': 200}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 24,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###2.3 output\r\n",
        "output_1=[]\r\n",
        "output_2=[]\r\n",
        "output_shoool=[]\r\n",
        "for s in list_title_clean:\r\n",
        "    i=list_title_clean.index(s)\r\n",
        "    top_words_temp=top_words.copy()\r\n",
        "    word_group_1=[]\r\n",
        "    word_group_2=[]\r\n",
        "    for w in top_words:\r\n",
        "        word_first=''\r\n",
        "        if w in s:\r\n",
        "            word_first=w\r\n",
        "            word_group_1.append(str(word_dict.get(w)))\r\n",
        "            word_group_1.append('-1')\r\n",
        "            word_group_2.append(w)\r\n",
        "            #print(word_first)\r\n",
        "            if w in top_words_temp:\r\n",
        "                top_words_temp.remove(w)\r\n",
        "            else:\r\n",
        "                print(w)\r\n",
        "            for w1 in top_words_temp:\r\n",
        "                if w1 in s:\r\n",
        "                    word_group_1.append(str(word_dict.get(word_first))+' ' +str(word_dict.get(w1)))\r\n",
        "                    word_group_1.append('-1')\r\n",
        "                    word_group_2.append(word_first+' ' +w1)\r\n",
        "    word_group_1.append('-2')\r\n",
        "    #print(word_group)\r\n",
        "    l=''\r\n",
        "    for s in word_group_1:\r\n",
        "        l=l+' '+s\r\n",
        "    l=l[1:]\r\n",
        "    if l!='-2':\r\n",
        "        output_1.append(l)\r\n",
        "        output_shoool.append(list_school[i])\r\n",
        "       \r\n",
        "\r\n",
        "    if len(word_group_2)!=0:\r\n",
        "        output_2.append(word_group_2)\r\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkpool3",
              "session_id": 26,
              "statement_id": 33,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2020-12-08T03:58:12.3237335Z",
              "execution_start_time": "2020-12-08T03:58:12.3570648Z",
              "execution_finish_time": "2020-12-08T03:59:58.066869Z"
            },
            "text/plain": "StatementMeta(sparkpool3, 26, 33, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 31,
          "data": {
            "text/plain": ""
          },
          "metadata": {}
        }
      ],
      "execution_count": 31,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## output for top schools\r\n",
        "list_school_desc=[w[0] for w in dict_school_topcount]\r\n",
        "###2. deal with the two words phrase\r\n",
        "list_top_shool=list_school_desc[:10]\r\n",
        "list_top_shool"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkpool3",
              "session_id": 26,
              "statement_id": 30,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2020-12-08T03:52:58.1107595Z",
              "execution_start_time": "2020-12-08T03:52:58.1402639Z",
              "execution_finish_time": "2020-12-08T03:53:00.1642212Z"
            },
            "text/plain": "StatementMeta(sparkpool3, 26, 30, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 28,
          "data": {
            "text/plain": "['Massachusetts Institute of Technology, Cambridge, MA, USA', 'Technical University Munich, Germany', 'Georgia Institute of Technology, Atlanta, GA, USA', 'Dresden University of Technology, Germany', 'University of Satilde;o Paulo, Brazil', 'RWTH Aachen University, Germany', 'Karlsruhe Institute of Technology, Germany', 'Darmstadt University of Technology, Germany', 'Joseph Fourier University, Grenoble, France', 'University of Maryland, College Park, MD, USA']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 28,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### output top school\r\n",
        "output_title_top=[]\r\n",
        "output_school_top=[]\r\n",
        "for i in range(len(output_shoool)):\r\n",
        "    if output_shoool[i] in list_top_shool:\r\n",
        "        output_title_top.append(output_1[i])\r\n",
        "        output_school_top.append(output_shoool[i])\r\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkpool3",
              "session_id": 26,
              "statement_id": 45,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2020-12-08T04:11:00.5385674Z",
              "execution_start_time": "2020-12-08T04:11:00.570321Z",
              "execution_finish_time": "2020-12-08T04:11:02.6030461Z"
            },
            "text/plain": "StatementMeta(sparkpool3, 26, 45, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 43,
          "data": {
            "text/plain": ""
          },
          "metadata": {}
        }
      ],
      "execution_count": 43,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(output_title_top[:3])\r\n",
        "print(output_school_top[:3])"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkpool3",
              "session_id": 26,
              "statement_id": 46,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2020-12-08T04:11:07.436375Z",
              "execution_start_time": "2020-12-08T04:11:07.4679022Z",
              "execution_finish_time": "2020-12-08T04:11:09.5038723Z"
            },
            "text/plain": "StatementMeta(sparkpool3, 26, 46, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 44,
          "data": {
            "text/plain": "['2 -1 2 196 -1 196 -1 -2', '13 -1 13 38 -1 13 53 -1 13 54 -1 13 55 -1 13 63 -1 13 161 -1 38 -1 38 53 -1 38 54 -1 38 55 -1 38 63 -1 38 161 -1 53 -1 53 54 -1 53 55 -1 53 63 -1 53 161 -1 54 -1 54 55 -1 54 63 -1 54 161 -1 55 -1 55 63 -1 55 161 -1 63 -1 63 161 -1 161 -1 -2', '94 -1 94 112 -1 112 -1 -2']\n['RWTH Aachen University, Germany', 'University of Satilde;o Paulo, Brazil', 'Massachusetts Institute of Technology, Cambridge, MA, USA']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 44,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns = [\"value\"]\r\n",
        "\r\n",
        "df_title = spark.createDataFrame(data=[[p] for p in output_title_top],schema =columns)\r\n",
        "df_title.coalesce(1).write.format(\"text\").option(\"header\", \"false\").mode(\"overwrite\").save('adl://cp-bizops-c15.azuredatalakestore.net/local/users/lowen/UIUC/dblp_title.txt')\r\n",
        "\r\n",
        "df_school = spark.createDataFrame(data=[[p] for p in output_school_top],schema =columns)\r\n",
        "df_school.coalesce(1).write.format(\"text\").option(\"header\", \"false\").mode(\"overwrite\").save('adl://cp-bizops-c15.azuredatalakestore.net/local/users/lowen/UIUC/dblp_school.txt')\r\n",
        "\r\n",
        "\r\n",
        "print(df_title.count(),df_school.count())"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkpool3",
              "session_id": 26,
              "statement_id": 70,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2020-12-08T04:28:19.1457063Z",
              "execution_start_time": "2020-12-08T04:28:19.1732062Z",
              "execution_finish_time": "2020-12-08T04:28:25.2760628Z"
            },
            "text/plain": "StatementMeta(sparkpool3, 26, 70, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 68,
          "data": {
            "text/plain": "9573 9573"
          },
          "metadata": {}
        }
      ],
      "execution_count": 68,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "#df_dict=pd.DataFrame.from_dict(word_dict[0])\r\n",
        "list_word_top= [[key +' '+str(value)] for key, value in word_dict.items()]\r\n",
        "\r\n",
        "df_word = spark.createDataFrame(data=list_word_top,schema =columns)\r\n",
        "df_word.coalesce(1).write.format(\"text\").option(\"header\", \"false\").mode(\"overwrite\").save('adl://cp-bizops-c15.azuredatalakestore.net/local/users/lowen/UIUC/dblp_word.txt')\r\n",
        "#display(df_word.limit(5))\r\n",
        "\r\n",
        "list_word_top[:3]"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkpool3",
              "session_id": 26,
              "statement_id": 75,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2020-12-08T04:29:20.7597569Z",
              "execution_start_time": "2020-12-08T04:29:20.7874525Z",
              "execution_finish_time": "2020-12-08T04:29:24.862244Z"
            },
            "text/plain": "StatementMeta(sparkpool3, 26, 75, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 73,
          "data": {
            "text/plain": "[['systems 1'], ['based 2'], ['pour 3']]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 73,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "sessionOptions": {
      "driverMemory": "56g",
      "driverCores": 8,
      "executorMemory": "56g",
      "executorCores": 8,
      "numExecutors": 3,
      "keepAliveTimeout": 30,
      "conf": {
        "spark.dynamicAllocation.enabled": "false",
        "spark.dynamicAllocation.minExecutors": "3",
        "spark.dynamicAllocation.maxExecutors": "3"
      }
    },
    "saveOutput": true,
    "language_info": {
      "name": "scala",
      "version": "2.11.12",
      "mimetype": "text/x-scala",
      "file_extension": ".scala",
      "pygments_lexer": "scala",
      "codemirror_mode": "scala",
      "nbconvert_exporter": "scala"
    },
    "a365ComputeOptions": {
      "nodeSize": "Medium",
      "auth": {
        "authResource": "https://dev.azuresynapse.net",
        "type": "AAD"
      },
      "name": "sparkpool3",
      "nodeCount": 10,
      "endpoint": "https://dsasa.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sparkpool3",
      "automaticScaleJobs": false,
      "type": "Spark",
      "id": "/subscriptions/523020eb-954d-4d10-b0fa-9b2e70996e93/resourceGroups/DataSolution/providers/Microsoft.Synapse/workspaces/dsasa/bigDataPools/sparkpool3",
      "sparkVersion": "2.4",
      "extraHeader": {}
    },
    "microsoft": {
      "language": "python"
    },
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}